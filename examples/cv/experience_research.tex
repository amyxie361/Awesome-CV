%-------------------------------------------------------------------------------
%	SECTION TITLE
%-------------------------------------------------------------------------------
\cvsection{Projects}


%-------------------------------------------------------------------------------
%	CONTENT
%-------------------------------------------------------------------------------
\begin{cventries}

%---------------------------------------------------------

 \cventry
    {University of Waterloo}
    {Pertaining Sequence to Sequence Model for Chinese Conversation} % Job title
    {Advisor: Ming Li, \& Jimmy Lin} % Location
    {June 2020 - Present} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Trained sequence to sequence transformer models on Chinese forum datasets with \textbf{PyTorch}.}
        \item {Modified positional embedding with sentence and paragraph information.}
      \end{cvitems}
    }
    
   \cventry
    {University of Waterloo}
    {Introduce tree-structure information into question generation} % Job title
    {Advisor: Ming Li} % Location
    {Jan 2020 - April 2020} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Researched on add parsing tree into sentence generation to help generate more logic meaningful questions.}
        \item {Parsing tree encoder outperforms universal sentence encoder under the encoder-decoder framework.}
      \end{cvitems}
    }
    
 \cventry
    {University of Waterloo}
    {Data Augmentation for Open Domain Question Answering.} % Job title
    {Advisor: Ming Li, \& Jimmy Lin} % Location
    {June 2019 - Sept 2019} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Researched on improving open domain question answering system's performance using distantly supervised data under the \textbf{TensorFlow} framework.}
        \item {Improved the system's performance by 10\% exact match rate on SQuAD 1.1 and established new baselines on Chinese reading comprehension datasets: CMRC and DRCD.}
      \end{cvitems}
    }
    
  \cventry
    {University of Waterloo}
    {{\href{https://github.com/amyxie361/CS651_Paper_recommendation}{\underline{Paper Recommendation using GraphX}}}} % Job title
    {Advisor: Adam Roegiest} % Location
    {Jan. 2019 - April 2019} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Applied \textbf{GraphX} to build an academic paper recommendation system.}
        \item {Implemented PageRank, keyword filtering, and pattern finding algorithms in GraphX and compared the framework against \textbf{MapReduce} on \textbf{Hadoop}.}
        \item {Applied the algorithm on a citation network to give recommend papers, taking usersâ€™ interest into account. }
      \end{cvitems}
    }

\cventry
    {University of Waterloo}
    {{\href{https://github.com/amyxie361/CS886}{\underline{Contextual Decomposition for Rationalizing LSTM Predictions}}}} % Job title
    {Advisor: {\href{https://cs.uwaterloo.ca/~y328yu/}{\underline{Yaoliang Yu}}}} % Location
    {Sept. 2018 - Nov 2018} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
        \item {Decomposed and analyzed LSTM model in token level to understand the effectiveness source of the model based on named entity detection task with \textbf{PyTorch}.}
        \item {Implemented and modified multi-view concept to understand the learned weight in the two-directions of LSTM model.}
        \item {Traced the source of the effective source of LSTM models and concluded the most effectiveness comes from embedding.}
      \end{cvitems}
    }
        
      \cventry
     {Shanghai Key Laboratory of Intelligent Information Processing, Fudan University} 
    {BioASQ: Question Answering Based on Biomedical Paper Database} % Job title
    {Advisor: Shanfeng Zhu \& Yimin Wei} % Location
    {July. 2017 - April. 2018} % Date(s)
    {
      \begin{cvitems} % Description(s) of tasks/responsibilities
	\item {Introduce occurrence possibility of words as the representation of answers for question answering.}
	\item {Adapted source code from TensorFlow for text processing including applying skip gram algorithm for word embedding matrix training.}
	\item {Constructed Bidirectional LSTM Recurrent Neural Networks under \textbf{Tensorflow} framework and introduced attention mechanism based on questions.}
	\item {Adjusted the model and achieved average Factoid MRR of 0.1615, List F measure of 0.1353.}
      \end{cvitems}
    }


    
\end{cventries}
